{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e25637",
   "metadata": {},
   "source": [
    "# 2.2 Task 1: Evaluation of the word2vec-google-news-300 Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f24938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domen\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e326e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_adapt_by_suffix', '_load_specials', '_log_evaluate_word_analogies', '_save_specials', '_smart_save', '_upconvert_old_d2vkv', '_upconvert_old_vocab', 'add_lifecycle_event', 'add_vector', 'add_vectors', 'allocate_vecattrs', 'closer_than', 'cosine_similarities', 'distance', 'distances', 'doesnt_match', 'evaluate_word_analogies', 'evaluate_word_pairs', 'expandos', 'fill_norms', 'get_index', 'get_normed_vectors', 'get_vecattr', 'get_vector', 'has_index_for', 'index2entity', 'index2word', 'index_to_key', 'init_sims', 'intersect_word2vec_format', 'key_to_index', 'lifecycle_events', 'load', 'load_word2vec_format', 'log_accuracy', 'log_evaluate_word_pairs', 'mapfile_path', 'most_similar', 'most_similar_cosmul', 'most_similar_to_given', 'n_similarity', 'next_index', 'norms', 'rank', 'rank_by_centrality', 'relative_cosine_similarity', 'resize_vectors', 'save', 'save_word2vec_format', 'set_vecattr', 'similar_by_key', 'similar_by_vector', 'similar_by_word', 'similarity', 'similarity_unseen_docs', 'sort_by_descending_frequency', 'unit_normalize_all', 'vector_size', 'vectors', 'vectors_norm', 'vocab', 'wmdistance', 'word_vec', 'words_closer_than']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29611f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tremendously\n",
      "0.19348016\n",
      "0.19348016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_load_specials',\n",
       " '_save_specials',\n",
       " '_smart_save',\n",
       " 'add_lifecycle_event',\n",
       " 'exponent',\n",
       " 'keyedvectors',\n",
       " 'kwargs',\n",
       " 'load',\n",
       " 'most_similar',\n",
       " 'save',\n",
       " 'threshold']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test the \"most_similar_to_given\" method!\n",
    "print(model.most_similar_to_given(\"enormously\", [\"test\", \"tremendously\", \"unique\"]))\n",
    "v1 = model.get_vector(\"tremendously\")\n",
    "v2 = model.get_vector(\"unique\")\n",
    "v3 = model.get_vector(\"tremendously\")\n",
    "print(model.similarity(\"tremendously\", \"unique\"))\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = dot(v1, v2)/(norm(v1)*norm(v2))\n",
    "print(cos_sim)\n",
    "\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
    "test = WordEmbeddingSimilarityIndex(keyedvectors=[v1])\n",
    "dir(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776da7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tremendously correct\n",
      "stipulations correct\n",
      "randomly correct\n",
      "conspicuous correct\n",
      "pinnacle correct\n",
      "imperfect correct\n",
      "desperately correct\n",
      "eaten correct\n",
      "coming correct\n",
      "succinctly correct\n",
      "ceremonies wrong\n",
      "restless wrong\n",
      "accelerate correct\n",
      "generosity wrong\n",
      "imaginative correct\n",
      "demonstrated correct\n",
      "continually correct\n",
      "subjects correct\n",
      "impress wrong\n",
      "expensive correct\n",
      "acknowledged correct\n",
      "location correct\n",
      "earn correct\n",
      "frequently correct\n",
      "relaxed correct\n",
      "argument correct\n",
      "thin correct\n",
      "planned correct\n",
      "limitless correct\n",
      "prickly wrong\n",
      "imposed correct\n",
      "skillfully correct\n",
      "commercialize wrong\n",
      "differences correct\n",
      "productive correct\n",
      "unequaled correct\n",
      "uniquely correct\n",
      "color correct\n",
      "rear correct\n",
      "accentuate correct\n",
      "hurriedly correct\n",
      "mild correct\n",
      "smile correct\n",
      "orally correct\n",
      "doctor correct\n",
      "basically correct\n",
      "useful wrong\n",
      "positioned correct\n",
      "major correct\n",
      "gradually correct\n",
      "constructed correct\n",
      "jobs correct\n",
      "improbable correct\n",
      "apathetically correct\n",
      "chronicles correct\n",
      "furiously correct\n",
      "remembered wrong\n",
      "mastery correct\n",
      "devised correct\n",
      "potential correct\n",
      "broadly correct\n",
      "prolonged correct\n",
      "dangerous correct\n",
      "None guess\n",
      "disperse correct\n",
      "chiefly correct\n",
      "conversational correct\n",
      "settled correct\n",
      "possible correct\n",
      "rapidly correct\n",
      "proportion correct\n",
      "postponed wrong\n",
      "alike correct\n",
      "solve correct\n",
      "enough correct\n",
      "manner correct\n",
      "sold correct\n",
      "larger correct\n",
      "origins correct\n",
      "ordinarily correct\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('synonyms.csv', newline='') as csvfile:\n",
    "    \n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    # Skip the first row of the csv\n",
    "    next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        word = row[0]\n",
    "        answer = row[1]\n",
    "        options = row[2:]\n",
    "        \n",
    "        guess_word = None\n",
    "        label = None\n",
    "        \n",
    "        try:\n",
    "            guess_word = model.most_similar_to_given(word, options)\n",
    "            label = \"correct\" if answer == guess_word else \"wrong\"\n",
    "        except KeyError:\n",
    "            label = \"guess\"\n",
    "        \n",
    "        print(guess_word, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6efd86c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "guess",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-5ba7110704fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"guess\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mLabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[1;31m# print(\"guess\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\enum.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: guess"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "from enum import Enum\n",
    "class Labels(Enum):\n",
    "    GUESS = \"guess\"\n",
    "    CORRECT = \"correct\"\n",
    "    WRONG = \"wrong\"\n",
    "\n",
    "def compute_most_similar_term(question_word, options):\n",
    "    sim = None\n",
    "    guess_word = None\n",
    "    for option in options:\n",
    "        try:\n",
    "            current = model.similarity(question_word, option)\n",
    "            if not sim or current > sim:\n",
    "                sim = current\n",
    "                guess_word = option\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return (guess_word, sim)\n",
    "\n",
    "with open('synonyms.csv', newline='') as csvfile:\n",
    "    \n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    # Skip the first row of the csv\n",
    "    next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        question_word = row[0]\n",
    "        answer_word = row[1]\n",
    "        options = row[2:]\n",
    "        \n",
    "        guess_word = None\n",
    "        sim = None\n",
    "        label = None\n",
    "        guess = False\n",
    "        \n",
    "        question_word_vector = None\n",
    "        \n",
    "        try:\n",
    "            question_word_vector = model.get_vector(question_word)\n",
    "        except KeyError:\n",
    "            guess = True\n",
    "            label = \"guess\"\n",
    "        \n",
    "        if label == Labels.guess:\n",
    "            # print(\"guess\")\n",
    "            pass\n",
    "        else:\n",
    "            (guess_word, sim) = compute_most_similar_term(question_word, options)\n",
    "        \n",
    "        print(question_word, answer_word, guess_word, sim, sim==None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d0fd8d",
   "metadata": {},
   "source": [
    "# 2.3 Task 2: Comparison with Other Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885641c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c9990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
