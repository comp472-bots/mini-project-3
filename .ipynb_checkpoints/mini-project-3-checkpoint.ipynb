{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e25637",
   "metadata": {},
   "source": [
    "# 2.2 Task 1: Evaluation of the word2vec-google-news-300 Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f24938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domen\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e326e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_adapt_by_suffix', '_load_specials', '_log_evaluate_word_analogies', '_save_specials', '_smart_save', '_upconvert_old_d2vkv', '_upconvert_old_vocab', 'add_lifecycle_event', 'add_vector', 'add_vectors', 'allocate_vecattrs', 'closer_than', 'cosine_similarities', 'distance', 'distances', 'doesnt_match', 'evaluate_word_analogies', 'evaluate_word_pairs', 'expandos', 'fill_norms', 'get_index', 'get_normed_vectors', 'get_vecattr', 'get_vector', 'has_index_for', 'index2entity', 'index2word', 'index_to_key', 'init_sims', 'intersect_word2vec_format', 'key_to_index', 'lifecycle_events', 'load', 'load_word2vec_format', 'log_accuracy', 'log_evaluate_word_pairs', 'mapfile_path', 'most_similar', 'most_similar_cosmul', 'most_similar_to_given', 'n_similarity', 'next_index', 'norms', 'rank', 'rank_by_centrality', 'relative_cosine_similarity', 'resize_vectors', 'save', 'save_word2vec_format', 'set_vecattr', 'similar_by_key', 'similar_by_vector', 'similar_by_word', 'similarity', 'similarity_unseen_docs', 'sort_by_descending_frequency', 'unit_normalize_all', 'vector_size', 'vectors', 'vectors_norm', 'vocab', 'wmdistance', 'word_vec', 'words_closer_than']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29611f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tremendously\n",
      "0.19348016\n",
      "0.19348016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_load_specials',\n",
       " '_save_specials',\n",
       " '_smart_save',\n",
       " 'add_lifecycle_event',\n",
       " 'exponent',\n",
       " 'keyedvectors',\n",
       " 'kwargs',\n",
       " 'load',\n",
       " 'most_similar',\n",
       " 'save',\n",
       " 'threshold']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test the \"most_similar_to_given\" method!\n",
    "print(model.most_similar_to_given(\"enormously\", [\"test\", \"tremendously\", \"unique\"]))\n",
    "v1 = model.get_vector(\"tremendously\")\n",
    "v2 = model.get_vector(\"unique\")\n",
    "v3 = model.get_vector(\"tremendously\")\n",
    "print(model.similarity(\"tremendously\", \"unique\"))\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = dot(v1, v2)/(norm(v1)*norm(v2))\n",
    "print(cos_sim)\n",
    "\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
    "test = WordEmbeddingSimilarityIndex(keyedvectors=[v1])\n",
    "dir(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776da7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tremendously correct\n",
      "stipulations correct\n",
      "randomly correct\n",
      "conspicuous correct\n",
      "pinnacle correct\n",
      "imperfect correct\n",
      "desperately correct\n",
      "eaten correct\n",
      "coming correct\n",
      "succinctly correct\n",
      "ceremonies wrong\n",
      "restless wrong\n",
      "accelerate correct\n",
      "generosity wrong\n",
      "imaginative correct\n",
      "demonstrated correct\n",
      "continually correct\n",
      "subjects correct\n",
      "impress wrong\n",
      "expensive correct\n",
      "acknowledged correct\n",
      "location correct\n",
      "earn correct\n",
      "frequently correct\n",
      "relaxed correct\n",
      "argument correct\n",
      "thin correct\n",
      "planned correct\n",
      "limitless correct\n",
      "prickly wrong\n",
      "imposed correct\n",
      "skillfully correct\n",
      "commercialize wrong\n",
      "differences correct\n",
      "productive correct\n",
      "unequaled correct\n",
      "uniquely correct\n",
      "color correct\n",
      "rear correct\n",
      "accentuate correct\n",
      "hurriedly correct\n",
      "mild correct\n",
      "smile correct\n",
      "orally correct\n",
      "doctor correct\n",
      "basically correct\n",
      "useful wrong\n",
      "positioned correct\n",
      "major correct\n",
      "gradually correct\n",
      "constructed correct\n",
      "jobs correct\n",
      "improbable correct\n",
      "apathetically correct\n",
      "chronicles correct\n",
      "furiously correct\n",
      "remembered wrong\n",
      "mastery correct\n",
      "devised correct\n",
      "potential correct\n",
      "broadly correct\n",
      "prolonged correct\n",
      "dangerous correct\n",
      "None guess\n",
      "disperse correct\n",
      "chiefly correct\n",
      "conversational correct\n",
      "settled correct\n",
      "possible correct\n",
      "rapidly correct\n",
      "proportion correct\n",
      "postponed wrong\n",
      "alike correct\n",
      "solve correct\n",
      "enough correct\n",
      "manner correct\n",
      "sold correct\n",
      "larger correct\n",
      "origins correct\n",
      "ordinarily correct\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('synonyms.csv', newline='') as csvfile:\n",
    "    \n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    # Skip the first row of the csv\n",
    "    next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        word = row[0]\n",
    "        answer = row[1]\n",
    "        options = row[2:]\n",
    "        \n",
    "        guess_word = None\n",
    "        label = None\n",
    "        \n",
    "        try:\n",
    "            guess_word = model.most_similar_to_given(word, options)\n",
    "            label = \"correct\" if answer == guess_word else \"wrong\"\n",
    "        except KeyError:\n",
    "            label = \"guess\"\n",
    "        \n",
    "        print(guess_word, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "994cf357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enormously tremendously tremendously 0.8185792 correct\n",
      "provisions stipulations stipulations 0.5333138 correct\n",
      "haphazardly randomly randomly 0.4860184 correct\n",
      "prominent conspicuous conspicuous 0.41725057 correct\n",
      "zenith pinnacle pinnacle 0.71583366 correct\n",
      "flawed imperfect imperfect 0.5620899 correct\n",
      "urgently desperately desperately 0.5280758 correct\n",
      "consumed eaten eaten 0.5504953 correct\n",
      "advent coming coming 0.10894986 correct\n",
      "concisely succinctly succinctly 0.59967554 correct\n",
      "salutes greetings ceremonies 0.33907863 wrong\n",
      "solitary alone restless 0.2693128 wrong\n",
      "hasten accelerate accelerate 0.58082795 correct\n",
      "perseverance endurance generosity 0.47843152 wrong\n",
      "fanciful imaginative imaginative 0.5728073 correct\n",
      "showed demonstrated demonstrated 0.5404576 correct\n",
      "constantly continually continually 0.8584364 correct\n",
      "issues subjects subjects 0.37114686 correct\n",
      "furnish supply impress 0.26941985 wrong\n",
      "costly expensive expensive 0.7346716 correct\n",
      "recognized acknowledged acknowledged 0.4111669 correct\n",
      "spot location location 0.3330908 correct\n",
      "make earn earn 0.347332 correct\n",
      "often frequently frequently 0.82612216 correct\n",
      "easygoing relaxed relaxed 0.5343206 correct\n",
      "debate argument argument 0.4837022 correct\n",
      "narrow thin thin 0.3514272 correct\n",
      "arranged planned planned 0.48471344 correct\n",
      "infinite limitless limitless 0.7255815 correct\n",
      "showy striking prickly 0.35533834 wrong\n",
      "levied imposed imposed 0.58303946 correct\n",
      "deftly skillfully skillfully 0.81815046 correct\n",
      "distribute circulate commercialize 0.42393982 wrong\n",
      "discrepancies differences differences 0.6154876 correct\n",
      "prolific productive productive 0.4121393 correct\n",
      "unmatched unequaled unequaled 0.817456 correct\n",
      "peculiarly uniquely uniquely 0.56227195 correct\n",
      "hue color color 0.5208082 correct\n",
      "hind rear rear 0.4229884 correct\n",
      "highlight accentuate accentuate 0.500334 correct\n",
      "hastily hurriedly hurriedly 0.73217213 correct\n",
      "temperate mild mild 0.46214446 correct\n",
      "grin smile smile 0.86040103 correct\n",
      "verbally orally orally 0.39360282 correct\n",
      "physician doctor doctor 0.7806021 correct\n",
      "essentially basically basically 0.8192141 correct\n",
      "keen sharp useful 0.2714343 wrong\n",
      "situated positioned positioned 0.38777462 correct\n",
      "principal major major 0.1930734 correct\n",
      "slowly gradually gradually 0.76532316 correct\n",
      "built constructed constructed 0.77348197 correct\n",
      "tasks jobs jobs 0.18034038 correct\n",
      "unlikely improbable improbable 0.5156869 correct\n",
      "halfheartedly apathetically apathetically 0.38231403 correct\n",
      "annals chronicles chronicles 0.2840163 correct\n",
      "wildly furiously furiously 0.34518188 correct\n",
      "hailed acclaimed remembered 0.40972707 wrong\n",
      "command mastery mastery 0.22942546 correct\n",
      "concocted devised devised 0.62262404 correct\n",
      "prospective potential potential 0.560609 correct\n",
      "generally broadly broadly 0.48017433 correct\n",
      "sustained prolonged prolonged 0.4194923 correct\n",
      "perilous dangerous dangerous 0.6077719 correct\n",
      "tranquillity peacefulness None None guess\n",
      "dissipate disperse disperse 0.38458365 correct\n",
      "primarily chiefly chiefly 0.6944755 correct\n",
      "colloquial conversational conversational 0.52059805 correct\n",
      "resolved settled settled 0.5406781 correct\n",
      "feasible possible possible 0.4911326 correct\n",
      "expeditiously rapidly rapidly 0.30607742 correct\n",
      "percentage proportion proportion 0.57497144 correct\n",
      "terminated ended postponed 0.3322972 wrong\n",
      "uniform alike alike 0.12608492 correct\n",
      "figure solve solve 0.21654359 correct\n",
      "sufficient enough enough 0.6044311 correct\n",
      "fashion manner manner 0.3540923 correct\n",
      "marketed sold sold 0.54296374 correct\n",
      "bigger larger larger 0.797631 correct\n",
      "roots origins origins 0.6270325 correct\n",
      "normally ordinarily ordinarily 0.7208079 correct\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from enum import Enum\n",
    "\n",
    "class Labels(Enum):\n",
    "    GUESS = \"guess\"\n",
    "    CORRECT = \"correct\"\n",
    "    WRONG = \"wrong\"\n",
    "\n",
    "def compute_most_similar_term(question_word: str, options: List[str]):\n",
    "    similarity = None\n",
    "    guess_word = None\n",
    "    for option in options:\n",
    "        try:\n",
    "            current = model.similarity(question_word, option)\n",
    "            if not similarity or current > similarity:\n",
    "                similarity = current\n",
    "                guess_word = option\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return (guess_word, similarity)\n",
    "\n",
    "def compute_synonyms():\n",
    "    with open('synonyms.csv', newline='') as csvfile:\n",
    "\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "        # Skip the first row of the csv\n",
    "        next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            question_word = row[0]\n",
    "            answer_word = row[1]\n",
    "            options = row[2:]\n",
    "\n",
    "            guess_word = None\n",
    "            similarity = None\n",
    "            label = None\n",
    "            guess = False\n",
    "\n",
    "            question_word_vector = None\n",
    "\n",
    "            try:\n",
    "                question_word_vector = model.get_vector(question_word)\n",
    "            except KeyError:\n",
    "                guess = True\n",
    "                label = Labels.GUESS\n",
    "\n",
    "            if label == Labels.GUESS:\n",
    "                pass\n",
    "            else:\n",
    "                (guess_word, similarity) = compute_most_similar_term(question_word, options)\n",
    "                label = Labels.CORRECT if answer_word == guess_word else Labels.WRONG\n",
    "\n",
    "            print(question_word, answer_word, guess_word, similarity, label.value)\n",
    "            \n",
    "compute_synonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d0fd8d",
   "metadata": {},
   "source": [
    "# 2.3 Task 2: Comparison with Other Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885641c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c9990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
